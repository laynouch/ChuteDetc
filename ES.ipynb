{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "sns.set_theme(color_codes=True)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "train_df = pd.read_csv(\"C:/Users/dawou/OneDrive/Bureau/ML/ChuteDetc/Train.csv\")\n",
    "test_df = pd.read_csv('C:/Users/dawou/OneDrive/Bureau/ML/ChuteDetc/Test.csv')\n",
    "\n",
    "train_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "test_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "X_train = train_df.drop(['fall', 'label'], axis=1)\n",
    "y_train = train_df['fall']\n",
    "X_test = test_df.drop(['fall', 'label'], axis=1)\n",
    "y_test = test_df['fall']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the TensorFlow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate=0.01, dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap the model with KerasClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(model=create_model, verbose=0)\n",
    "param_dist = {\n",
    "    'model__learning_rate': [0.001, 0.01, 0.1],\n",
    "    'model__dropout_rate': [0.2, 0.3, 0.4],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [50, 100, 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform hyperparameter tuning with RandomizedSearchCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist,\n",
    "                                   n_iter=10, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "best_params = random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the final model with the best hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "45/45 - 4s - 81ms/step - accuracy: 0.8403 - loss: 0.4446 - val_accuracy: 0.9579 - val_loss: 0.2017\n",
      "Epoch 2/100\n",
      "45/45 - 0s - 5ms/step - accuracy: 0.9552 - loss: 0.1752 - val_accuracy: 0.9579 - val_loss: 0.1054\n",
      "Epoch 3/100\n",
      "45/45 - 0s - 5ms/step - accuracy: 0.9664 - loss: 0.1132 - val_accuracy: 0.9579 - val_loss: 0.0877\n",
      "Epoch 4/100\n",
      "45/45 - 0s - 5ms/step - accuracy: 0.9664 - loss: 0.0969 - val_accuracy: 0.9691 - val_loss: 0.0765\n",
      "Epoch 5/100\n",
      "45/45 - 0s - 5ms/step - accuracy: 0.9692 - loss: 0.0863 - val_accuracy: 0.9719 - val_loss: 0.0749\n",
      "Epoch 6/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9762 - loss: 0.0749 - val_accuracy: 0.9719 - val_loss: 0.0746\n",
      "Epoch 7/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9755 - loss: 0.0728 - val_accuracy: 0.9691 - val_loss: 0.0730\n",
      "Epoch 8/100\n",
      "45/45 - 0s - 5ms/step - accuracy: 0.9776 - loss: 0.0689 - val_accuracy: 0.9691 - val_loss: 0.0734\n",
      "Epoch 9/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9783 - loss: 0.0656 - val_accuracy: 0.9691 - val_loss: 0.0743\n",
      "Epoch 10/100\n",
      "45/45 - 0s - 5ms/step - accuracy: 0.9776 - loss: 0.0686 - val_accuracy: 0.9691 - val_loss: 0.0726\n",
      "Epoch 11/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9776 - loss: 0.0611 - val_accuracy: 0.9691 - val_loss: 0.0733\n",
      "Epoch 12/100\n",
      "45/45 - 0s - 5ms/step - accuracy: 0.9790 - loss: 0.0602 - val_accuracy: 0.9691 - val_loss: 0.0748\n",
      "Epoch 13/100\n",
      "45/45 - 0s - 5ms/step - accuracy: 0.9818 - loss: 0.0560 - val_accuracy: 0.9691 - val_loss: 0.0744\n",
      "Epoch 14/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9818 - loss: 0.0560 - val_accuracy: 0.9691 - val_loss: 0.0757\n",
      "Epoch 15/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9811 - loss: 0.0554 - val_accuracy: 0.9691 - val_loss: 0.0760\n",
      "Epoch 16/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9825 - loss: 0.0505 - val_accuracy: 0.9691 - val_loss: 0.0768\n",
      "Epoch 17/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9832 - loss: 0.0547 - val_accuracy: 0.9691 - val_loss: 0.0768\n",
      "Epoch 18/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9804 - loss: 0.0578 - val_accuracy: 0.9691 - val_loss: 0.0755\n",
      "Epoch 19/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9839 - loss: 0.0569 - val_accuracy: 0.9691 - val_loss: 0.0754\n",
      "Epoch 20/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9811 - loss: 0.0526 - val_accuracy: 0.9691 - val_loss: 0.0754\n",
      "Epoch 21/100\n",
      "45/45 - 0s - 5ms/step - accuracy: 0.9818 - loss: 0.0518 - val_accuracy: 0.9691 - val_loss: 0.0765\n",
      "Epoch 22/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9839 - loss: 0.0501 - val_accuracy: 0.9691 - val_loss: 0.0777\n",
      "Epoch 23/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9811 - loss: 0.0514 - val_accuracy: 0.9691 - val_loss: 0.0780\n",
      "Epoch 24/100\n",
      "45/45 - 0s - 7ms/step - accuracy: 0.9860 - loss: 0.0492 - val_accuracy: 0.9691 - val_loss: 0.0793\n",
      "Epoch 25/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9846 - loss: 0.0495 - val_accuracy: 0.9691 - val_loss: 0.0798\n",
      "Epoch 26/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9860 - loss: 0.0464 - val_accuracy: 0.9719 - val_loss: 0.0802\n",
      "Epoch 27/100\n",
      "45/45 - 0s - 5ms/step - accuracy: 0.9832 - loss: 0.0498 - val_accuracy: 0.9691 - val_loss: 0.0798\n",
      "Epoch 28/100\n",
      "45/45 - 0s - 5ms/step - accuracy: 0.9839 - loss: 0.0442 - val_accuracy: 0.9719 - val_loss: 0.0819\n",
      "Epoch 29/100\n",
      "45/45 - 0s - 5ms/step - accuracy: 0.9811 - loss: 0.0482 - val_accuracy: 0.9719 - val_loss: 0.0817\n",
      "Epoch 30/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9853 - loss: 0.0486 - val_accuracy: 0.9719 - val_loss: 0.0816\n",
      "Epoch 31/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9825 - loss: 0.0513 - val_accuracy: 0.9747 - val_loss: 0.0799\n",
      "Epoch 32/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9846 - loss: 0.0457 - val_accuracy: 0.9719 - val_loss: 0.0799\n",
      "Epoch 33/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9839 - loss: 0.0473 - val_accuracy: 0.9719 - val_loss: 0.0807\n",
      "Epoch 34/100\n",
      "45/45 - 0s - 9ms/step - accuracy: 0.9846 - loss: 0.0494 - val_accuracy: 0.9719 - val_loss: 0.0807\n",
      "Epoch 35/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9867 - loss: 0.0422 - val_accuracy: 0.9747 - val_loss: 0.0802\n",
      "Epoch 36/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9853 - loss: 0.0435 - val_accuracy: 0.9719 - val_loss: 0.0826\n",
      "Epoch 37/100\n",
      "45/45 - 0s - 5ms/step - accuracy: 0.9818 - loss: 0.0457 - val_accuracy: 0.9719 - val_loss: 0.0829\n",
      "Epoch 38/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9825 - loss: 0.0417 - val_accuracy: 0.9719 - val_loss: 0.0837\n",
      "Epoch 39/100\n",
      "45/45 - 0s - 5ms/step - accuracy: 0.9839 - loss: 0.0422 - val_accuracy: 0.9719 - val_loss: 0.0832\n",
      "Epoch 40/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9867 - loss: 0.0382 - val_accuracy: 0.9719 - val_loss: 0.0843\n",
      "Epoch 41/100\n",
      "45/45 - 0s - 5ms/step - accuracy: 0.9853 - loss: 0.0410 - val_accuracy: 0.9719 - val_loss: 0.0842\n",
      "Epoch 42/100\n",
      "45/45 - 0s - 5ms/step - accuracy: 0.9846 - loss: 0.0433 - val_accuracy: 0.9719 - val_loss: 0.0867\n",
      "Epoch 43/100\n",
      "45/45 - 0s - 5ms/step - accuracy: 0.9846 - loss: 0.0446 - val_accuracy: 0.9719 - val_loss: 0.0863\n",
      "Epoch 44/100\n",
      "45/45 - 0s - 5ms/step - accuracy: 0.9860 - loss: 0.0438 - val_accuracy: 0.9719 - val_loss: 0.0865\n",
      "Epoch 45/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9853 - loss: 0.0408 - val_accuracy: 0.9719 - val_loss: 0.0891\n",
      "Epoch 46/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9853 - loss: 0.0414 - val_accuracy: 0.9719 - val_loss: 0.0894\n",
      "Epoch 47/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9853 - loss: 0.0391 - val_accuracy: 0.9719 - val_loss: 0.0866\n",
      "Epoch 48/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9846 - loss: 0.0422 - val_accuracy: 0.9719 - val_loss: 0.0865\n",
      "Epoch 49/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9860 - loss: 0.0448 - val_accuracy: 0.9719 - val_loss: 0.0885\n",
      "Epoch 50/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9867 - loss: 0.0433 - val_accuracy: 0.9719 - val_loss: 0.0865\n",
      "Epoch 51/100\n",
      "45/45 - 0s - 5ms/step - accuracy: 0.9874 - loss: 0.0400 - val_accuracy: 0.9719 - val_loss: 0.0872\n",
      "Epoch 52/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9867 - loss: 0.0354 - val_accuracy: 0.9719 - val_loss: 0.0893\n",
      "Epoch 53/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9853 - loss: 0.0410 - val_accuracy: 0.9719 - val_loss: 0.0907\n",
      "Epoch 54/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9867 - loss: 0.0390 - val_accuracy: 0.9719 - val_loss: 0.0913\n",
      "Epoch 55/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9867 - loss: 0.0397 - val_accuracy: 0.9719 - val_loss: 0.0882\n",
      "Epoch 56/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9860 - loss: 0.0340 - val_accuracy: 0.9719 - val_loss: 0.0899\n",
      "Epoch 57/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9867 - loss: 0.0351 - val_accuracy: 0.9719 - val_loss: 0.0912\n",
      "Epoch 58/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9860 - loss: 0.0376 - val_accuracy: 0.9719 - val_loss: 0.0945\n",
      "Epoch 59/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9853 - loss: 0.0410 - val_accuracy: 0.9719 - val_loss: 0.0891\n",
      "Epoch 60/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9874 - loss: 0.0344 - val_accuracy: 0.9719 - val_loss: 0.0907\n",
      "Epoch 61/100\n",
      "45/45 - 0s - 5ms/step - accuracy: 0.9895 - loss: 0.0364 - val_accuracy: 0.9719 - val_loss: 0.0932\n",
      "Epoch 62/100\n",
      "45/45 - 0s - 5ms/step - accuracy: 0.9881 - loss: 0.0396 - val_accuracy: 0.9719 - val_loss: 0.0932\n",
      "Epoch 63/100\n",
      "45/45 - 0s - 5ms/step - accuracy: 0.9874 - loss: 0.0355 - val_accuracy: 0.9719 - val_loss: 0.0946\n",
      "Epoch 64/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9860 - loss: 0.0362 - val_accuracy: 0.9719 - val_loss: 0.0982\n",
      "Epoch 65/100\n",
      "45/45 - 0s - 5ms/step - accuracy: 0.9895 - loss: 0.0381 - val_accuracy: 0.9719 - val_loss: 0.0977\n",
      "Epoch 66/100\n",
      "45/45 - 0s - 9ms/step - accuracy: 0.9867 - loss: 0.0351 - val_accuracy: 0.9719 - val_loss: 0.1002\n",
      "Epoch 67/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9874 - loss: 0.0368 - val_accuracy: 0.9719 - val_loss: 0.1002\n",
      "Epoch 68/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9881 - loss: 0.0318 - val_accuracy: 0.9719 - val_loss: 0.1008\n",
      "Epoch 69/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9853 - loss: 0.0353 - val_accuracy: 0.9719 - val_loss: 0.1024\n",
      "Epoch 70/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9881 - loss: 0.0358 - val_accuracy: 0.9719 - val_loss: 0.1035\n",
      "Epoch 71/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9874 - loss: 0.0330 - val_accuracy: 0.9719 - val_loss: 0.1045\n",
      "Epoch 72/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9839 - loss: 0.0400 - val_accuracy: 0.9719 - val_loss: 0.0994\n",
      "Epoch 73/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9867 - loss: 0.0381 - val_accuracy: 0.9719 - val_loss: 0.0960\n",
      "Epoch 74/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9867 - loss: 0.0361 - val_accuracy: 0.9719 - val_loss: 0.0977\n",
      "Epoch 75/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9867 - loss: 0.0315 - val_accuracy: 0.9719 - val_loss: 0.1007\n",
      "Epoch 76/100\n",
      "45/45 - 0s - 6ms/step - accuracy: 0.9895 - loss: 0.0363 - val_accuracy: 0.9719 - val_loss: 0.1013\n",
      "Epoch 77/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9874 - loss: 0.0379 - val_accuracy: 0.9719 - val_loss: 0.1012\n",
      "Epoch 78/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9888 - loss: 0.0352 - val_accuracy: 0.9719 - val_loss: 0.1033\n",
      "Epoch 79/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9909 - loss: 0.0291 - val_accuracy: 0.9719 - val_loss: 0.1067\n",
      "Epoch 80/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9860 - loss: 0.0379 - val_accuracy: 0.9719 - val_loss: 0.1077\n",
      "Epoch 81/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9909 - loss: 0.0312 - val_accuracy: 0.9719 - val_loss: 0.1074\n",
      "Epoch 82/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9874 - loss: 0.0338 - val_accuracy: 0.9719 - val_loss: 0.1054\n",
      "Epoch 83/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9860 - loss: 0.0370 - val_accuracy: 0.9719 - val_loss: 0.1047\n",
      "Epoch 84/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9867 - loss: 0.0384 - val_accuracy: 0.9719 - val_loss: 0.1012\n",
      "Epoch 85/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9881 - loss: 0.0372 - val_accuracy: 0.9719 - val_loss: 0.1048\n",
      "Epoch 86/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9867 - loss: 0.0323 - val_accuracy: 0.9719 - val_loss: 0.1068\n",
      "Epoch 87/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9888 - loss: 0.0330 - val_accuracy: 0.9719 - val_loss: 0.1074\n",
      "Epoch 88/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9895 - loss: 0.0334 - val_accuracy: 0.9719 - val_loss: 0.1055\n",
      "Epoch 89/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9860 - loss: 0.0342 - val_accuracy: 0.9719 - val_loss: 0.1094\n",
      "Epoch 90/100\n",
      "45/45 - 0s - 9ms/step - accuracy: 0.9902 - loss: 0.0359 - val_accuracy: 0.9719 - val_loss: 0.1107\n",
      "Epoch 91/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9895 - loss: 0.0270 - val_accuracy: 0.9719 - val_loss: 0.1091\n",
      "Epoch 92/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9874 - loss: 0.0366 - val_accuracy: 0.9719 - val_loss: 0.1056\n",
      "Epoch 93/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9874 - loss: 0.0325 - val_accuracy: 0.9719 - val_loss: 0.1051\n",
      "Epoch 94/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9909 - loss: 0.0300 - val_accuracy: 0.9719 - val_loss: 0.1097\n",
      "Epoch 95/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9888 - loss: 0.0355 - val_accuracy: 0.9719 - val_loss: 0.1100\n",
      "Epoch 96/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9867 - loss: 0.0322 - val_accuracy: 0.9719 - val_loss: 0.1126\n",
      "Epoch 97/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9881 - loss: 0.0334 - val_accuracy: 0.9719 - val_loss: 0.1134\n",
      "Epoch 98/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9874 - loss: 0.0340 - val_accuracy: 0.9719 - val_loss: 0.1095\n",
      "Epoch 99/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9846 - loss: 0.0330 - val_accuracy: 0.9719 - val_loss: 0.1084\n",
      "Epoch 100/100\n",
      "45/45 - 0s - 4ms/step - accuracy: 0.9895 - loss: 0.0324 - val_accuracy: 0.9719 - val_loss: 0.1096\n"
     ]
    }
   ],
   "source": [
    "final_model = create_model(learning_rate=best_params['model__learning_rate'], dropout_rate=best_params['model__dropout_rate'])\n",
    "history = final_model.fit(X_train, y_train, \n",
    "                          epochs=best_params['epochs'], \n",
    "                          batch_size=best_params['batch_size'], \n",
    "                          validation_data=(X_test, y_test), \n",
    "                          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Performance du modèle\n",
      "Précision = 97.19%.\n",
      "La meilleure précision obtenue est : 97.19%.\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = (model.predict(test_features) > 0.5).astype(\"int32\")\n",
    "    predictions = np.ravel(predictions)  # Ensure predictions is a 1D array\n",
    "    accuracy = ((predictions == test_labels).sum() / test_labels.shape[0]) * 100\n",
    "    print('Performance du modèle')\n",
    "    print('Précision = {:0.2f}%.'.format(accuracy))\n",
    "    return accuracy\n",
    "\n",
    "accuracy = evaluate(final_model, X_test, y_test)\n",
    "print(f\"La meilleure précision obtenue est : {accuracy:.2f}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute '_get_save_spec'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[153], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m converter \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mTFLiteConverter\u001b[38;5;241m.\u001b[39mfrom_keras_model(model)\n\u001b[1;32m----> 3\u001b[0m tflmodel \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m( \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myourmodel.tflite\u001b[39m\u001b[38;5;124m'\u001b[39m , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m ) \n\u001b[0;32m      5\u001b[0m file\u001b[38;5;241m.\u001b[39mwrite( tflmodel )\n",
      "File \u001b[1;32mc:\\Users\\dawou\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1175\u001b[0m, in \u001b[0;36m_export_metrics.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(convert_func)\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1174\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 1175\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_and_export_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dawou\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1129\u001b[0m, in \u001b[0;36mTFLiteConverterBase._convert_and_export_metrics\u001b[1;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_conversion_params_metric()\n\u001b[0;32m   1128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mprocess_time()\n\u001b[1;32m-> 1129\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1130\u001b[0m elapsed_time_ms \u001b[38;5;241m=\u001b[39m (time\u001b[38;5;241m.\u001b[39mprocess_time() \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "File \u001b[1;32mc:\\Users\\dawou\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1641\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2.convert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m saved_model_convert_result:\n\u001b[0;32m   1638\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_convert_result\n\u001b[0;32m   1640\u001b[0m graph_def, input_tensors, output_tensors, frozen_func \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1641\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_freeze_keras_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1642\u001b[0m )\n\u001b[0;32m   1644\u001b[0m graph_def \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimize_tf_model(\n\u001b[0;32m   1645\u001b[0m     graph_def, input_tensors, output_tensors, frozen_func\n\u001b[0;32m   1646\u001b[0m )\n\u001b[0;32m   1648\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(TFLiteKerasModelConverterV2, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mconvert(\n\u001b[0;32m   1649\u001b[0m     graph_def, input_tensors, output_tensors\n\u001b[0;32m   1650\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dawou\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\convert_phase.py:215\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m    214\u001b[0m   report_error_message(\u001b[38;5;28mstr\u001b[39m(error))\n\u001b[1;32m--> 215\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m error \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dawou\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\convert_phase.py:205\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    204\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m ConverterError \u001b[38;5;28;01mas\u001b[39;00m converter_error:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m converter_error\u001b[38;5;241m.\u001b[39merrors:\n",
      "File \u001b[1;32mc:\\Users\\dawou\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1582\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2._freeze_keras_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1573\u001b[0m \u001b[38;5;66;03m# If the model's call is not a `tf.function`, then we need to first get its\u001b[39;00m\n\u001b[0;32m   1574\u001b[0m \u001b[38;5;66;03m# input signature from `model_input_signature` method. We can't directly\u001b[39;00m\n\u001b[0;32m   1575\u001b[0m \u001b[38;5;66;03m# call `trace_model_call` because otherwise the batch dimension is set\u001b[39;00m\n\u001b[0;32m   1576\u001b[0m \u001b[38;5;66;03m# to None.\u001b[39;00m\n\u001b[0;32m   1577\u001b[0m \u001b[38;5;66;03m# Once we have better support for dynamic shapes, we can remove this.\u001b[39;00m\n\u001b[0;32m   1578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keras_model\u001b[38;5;241m.\u001b[39mcall, _def_function\u001b[38;5;241m.\u001b[39mFunction):\n\u001b[0;32m   1579\u001b[0m   \u001b[38;5;66;03m# Pass `keep_original_batch_size=True` will ensure that we get an input\u001b[39;00m\n\u001b[0;32m   1580\u001b[0m   \u001b[38;5;66;03m# signature including the batch dimension specified by the user.\u001b[39;00m\n\u001b[0;32m   1581\u001b[0m   \u001b[38;5;66;03m# TODO(b/169898786): Use the Keras public API when TFLite moves out of TF\u001b[39;00m\n\u001b[1;32m-> 1582\u001b[0m   input_signature \u001b[38;5;241m=\u001b[39m \u001b[43m_model_input_signature\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1583\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_keras_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_original_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m   1584\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1586\u001b[0m \u001b[38;5;66;03m# TODO(b/169898786): Use the Keras public API when TFLite moves out of TF\u001b[39;00m\n\u001b[0;32m   1587\u001b[0m func \u001b[38;5;241m=\u001b[39m _trace_model_call(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keras_model, input_signature)\n",
      "File \u001b[1;32mc:\\Users\\dawou\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:84\u001b[0m, in \u001b[0;36mmodel_input_signature\u001b[1;34m(model, keep_original_batch_size)\u001b[0m\n\u001b[0;32m     82\u001b[0m   input_specs \u001b[38;5;241m=\u001b[39m input_specs[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m   input_specs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_save_spec\u001b[49m(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m     85\u001b[0m       dynamic_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m keep_original_batch_size)\n\u001b[0;32m     86\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m input_specs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute '_get_save_spec'"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('final_model.h5')\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflmodel = converter.convert()\n",
    "file = open( 'yourmodel.tflite' , 'wb' ) \n",
    "file.write( tflmodel )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
